{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYw1UOEQac44E2m6AUtPFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushanttwayana/Python_Projects/blob/main/_Mini_Projects_(contd).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7cf9q_9gqbh"
      },
      "outputs": [],
      "source": [
        "# ========================== Covid 19 Update Bot ===================================\n",
        "\n",
        "# please use an currently available url for fetching the data\n",
        "# pip install requests, win10toast\n",
        "# reuests library allows us to send requests to different websites\n",
        "# win10toast allows us to show notificitaion in windows\n",
        "\n",
        "import requests\n",
        "from win10toast import ToastNotifier\n",
        "import json # An API which allows us the as to be in json format\n",
        "import time\n",
        "\n",
        "def update():\n",
        "\n",
        "    r = requests.get('https://api.covid19api.com/all')\n",
        "    r.raise_for_status()  # Raise an exception for HTTP errors (e.g., 404)\n",
        "    data = r.json() # convert data into json format\n",
        "    # text = f'Confirmed Cases: {data[\"cases\"]}\\nDeaths: {data[\"deaths\"]}\\nRecovered: {data[\"recovered\"]}'\n",
        "    text = f'Confirmed Cases: {data[\"cases\"]}\\nDeaths: {data[\"deaths\"]}\\nRecovered: {data[\"recovered\"]}'\n",
        "\n",
        "    while True :\n",
        "        toast = ToastNotifier()\n",
        "        toast.show_toast(\"Covid-19 Updates\",text,duration = 20) #sleep after 20 seconds\n",
        "        time.sleep(60) #every 60 minute this notification will pop up again\n",
        "\n",
        "\n",
        "update()\n",
        "\n",
        "\n",
        "# ============================================\n",
        "\n",
        "# import requests\n",
        "# from win10toast import ToastNotifier\n",
        "# import time\n",
        "\n",
        "# def update():\n",
        "#     while True:\n",
        "#         # try:\n",
        "#             r = requests.get('https://coronavirus.jhu.edu/map.html')\n",
        "#             data = r.json()\n",
        "#             text = f'Confirmed Cases: {data[\"cases\"]}\\nDeaths: {data[\"deaths\"]}\\nRecovered: {data[\"recovered\"]}'\n",
        "#             toast = ToastNotifier()\n",
        "#             toast.show_toast(\"Covid-19 Updates\", text, duration=20)\n",
        "#             time.sleep(3600)  # Show the notification every 60 minutes\n",
        "\n",
        "#         # except Exception as e:\n",
        "#         #     print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     update()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== IMAGE TO TEXT ===================================\n",
        "# Use this link to download necessecary tesseract file \"github.com/UB-Mannheim/tesseract/wiki\"\n",
        "# pip install tesseract\n",
        "\n",
        "import pytesseract\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"D:\\vs code\\my_folder\\python\\Modules\\tesseract.exe\" # path to tesseract\n",
        "\n",
        "def convert() :\n",
        "    img  = Image.open('ocr_img1.png')\n",
        "    text = pytesseract.image_to_string(img)\n",
        "    print(text)\n",
        "\n",
        "convert()\n"
      ],
      "metadata": {
        "id": "Pd3M1BqnhEnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== TEXT TO SPEECH ===================================\n",
        "\n",
        "# pip install pyttsx3\n",
        "\n",
        "import pyttsx3\n",
        "\n",
        "data  = input(\"Enter text which you want to convert to speech:\\n\")\n",
        "\n",
        "engine = pyttsx3.init()\n",
        "# engine.say(\"I love my babes very much. Her name is Miss Sumina Awa\")\n",
        "engine.say(data)\n",
        "engine.runAndWait()"
      ],
      "metadata": {
        "id": "xnrBi9sHhVGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== SPEECH TO TEXT ===================================\n",
        "\n",
        "# pip install SpeechRecognition\n",
        "# pip install pyaudio\n",
        "\n",
        "import pyttsx3\n",
        "import speech_recognition as sr\n",
        "\n",
        "def get_audio() :\n",
        "\n",
        "    r = sr.Recognizer()\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Listening... Please say something!\")\n",
        "        audio = r.listen(source)\n",
        "        print(\"DONE!!\")\n",
        "\n",
        "    try:\n",
        "        text = r.recognize_google(audio)\n",
        "        print(\"You said : \"+ text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print('Sorry, I did not understand')\n",
        "        # print(e)\n",
        "\n",
        "get_audio()"
      ],
      "metadata": {
        "id": "oyU2N0iDh47F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== CHROME AUTOMATION ===================================\n",
        "\n",
        "import webbrowser as wb\n",
        "\n",
        "def web_auto():\n",
        "\n",
        "    # Path of the chrome in your device\n",
        "    chrome_path = \"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe %s\"\n",
        "\n",
        "    URLS = (\n",
        "        \"facebook.com\",\n",
        "        \"gmail.com\",\n",
        "        \"github.com/sushanttwayana/\"\n",
        "    )\n",
        "\n",
        "    for url in URLS :\n",
        "        print(\"opening:\" + url)\n",
        "        wb.get(chrome_path).open(url)\n",
        "\n",
        "web_auto()\n"
      ],
      "metadata": {
        "id": "wkzkBVDsh7Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== WEB CAM  ===================================\n",
        "\n",
        "# pip install opencv-python\n",
        "\n",
        "import cv2\n",
        "\n",
        "img_capture = cv2.VideoCapture(0) # id of the webcam as in laptop we have only 1 inbuilt webcam so it is assigned 1 , if you have multiple webcams assign it in similar way\n",
        "\n",
        "result = True\n",
        "\n",
        "while result :\n",
        "    ret, frame = img_capture.read()\n",
        "    cv2.imwrite('test1.jpg', frame)\n",
        "    result = False\n",
        "    print(\"Image Captured\")\n",
        "\n",
        "img_capture.release()\n"
      ],
      "metadata": {
        "id": "IHfgUXzzh8M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================  IMPLICATION OF JSON ===================================\n",
        "\n",
        "import json\n",
        "\n",
        "# Create a Python dictionary\n",
        "data = {\n",
        "    \"name\": \"John\",\n",
        "    \"age\": 30,\n",
        "    \"city\": \"New York\"\n",
        "}\n",
        "\n",
        "# Serialize the dictionary to a JSON string\n",
        "json_string = json.dumps(data)\n",
        "\n",
        "# Print the JSON string\n",
        "print(json_string)\n",
        "\n",
        "# Deserialize the JSON string back to a Python object (dictionary)\n",
        "decoded_data = json.loads(json_string)\n",
        "\n",
        "# Access data in the dictionary\n",
        "print(decoded_data[\"name\"])  # Outputs: John"
      ],
      "metadata": {
        "id": "8AUcy4HXh8qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== WEBCAM ===================================\n",
        "\n",
        "# pip install opencv-python\n",
        "\n",
        "import cv2\n",
        "\n",
        "img_capture = cv2.VideoCapture(0) # id of the webcam as in laptop we have only 1 inbuilt webcam so it is assigned 1 , if you have multiple webcams assign it in similar way\n",
        "\n",
        "result = True\n",
        "\n",
        "while result :\n",
        "    ret, frame = img_capture.read()\n",
        "    cv2.imwrite('test1.jpg', frame)\n",
        "    result = False\n",
        "    print(\"Image Captured\")\n",
        "\n",
        "img_capture.release()\n",
        "\n"
      ],
      "metadata": {
        "id": "UARygfBMh-ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== SCREEN RECORDER ===================================\n",
        "\n",
        "import cv2\n",
        "import numpy as np # allows us to create a multidimensional arrays\n",
        "from PIL import ImageGrab\n",
        "\n",
        "def screen_recorder():\n",
        "\n",
        "    # four character code(fourcc )\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter(\"output.avi\", fourcc, 5.0, (1366, 768))\n",
        "    # 5.0 represents the frame rate\n",
        "    # other represents the resolution of your screen\n",
        "\n",
        "    while True:\n",
        "        img = ImageGrab.grab()\n",
        "        img_np = np.array(img)\n",
        "        # open cv captures the image in BGR so we have to convert it into Corresponfing RGB color\n",
        "        frame = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n",
        "        cv2.imshow(\"ScreenRecoder\", frame)\n",
        "        out.write(frame) # write the frame in our screen\n",
        "\n",
        "        if cv2.waitKey(1) == 27 : # if user presses key 'k' then recording will stop\n",
        "            break\n",
        "\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()  # destroy all the previously created window screen\n",
        "\n",
        "screen_recorder()\n",
        "\n"
      ],
      "metadata": {
        "id": "PI6CjLfmwI08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== FACE DETECTION ===================================\n",
        "\n",
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalcatface.xml')\n",
        "\n",
        "def detect():\n",
        "\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    while True:\n",
        "\n",
        "        _, img = cap.read()\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # convert the imag into grayscale first\n",
        "\n",
        "        # multiple factors are provided where 1.1 represents the scale factor and upto 4 people can be dtetcted in the same image\n",
        "        face = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "        for (x, y, w, h) in face : # x-cordinate, y, width, height\n",
        "            # 2 is the thickness of rectangle, which we want to create around the face\n",
        "            # (255, 0, 0 ) represents blue color of the rectangle, we can specify the colot of rectangle here\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), (0,0,255), 2)\n",
        "\n",
        "            cv2.imshow(\"Face Detect\", img)\n",
        "\n",
        "         # Check if the user pressed the Escape key (ASCII code 27)\n",
        "        if cv2.waitKey(1) == 27:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "detect()"
      ],
      "metadata": {
        "id": "XUelhCGKwJOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== WEATHER APP ===================================\n",
        "\n",
        "# pip install bs4\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup as soup\n",
        "\n",
        "# search  = \"Weather in Bhaktapur, Nepal\"\n",
        "search = input(\"Please provide the city name where you want to know the weather as 'Weather In Tokyo:\\n'\")\n",
        "url = f\"https://www.google.com/search?&q={search}\" # this indicates the search paramter in the given url\n",
        "\n",
        "response=requests.get(url)   # get method to fetch data from a website and store it into response object\n",
        "\n",
        "s = soup(response.text,\"html.parser\") # This html parses/fetches the data from url\n",
        "\n",
        "update = s.find(\"div\", class_ = \"BNeawe\").text # built in class\n",
        "print (update)"
      ],
      "metadata": {
        "id": "1iIVTsO_wJkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== SCREENSHOT ===================================\n",
        "\n",
        "# pip install virtualenv -> allows us to create a virtual environment\n",
        "# pip install pyautogui\n",
        "\n",
        "import time\n",
        "import pyautogui\n",
        "\n",
        "def screenshot() :\n",
        "\n",
        "    name = int(round(time.time() * 1000))\n",
        "    name = 'D:/vs code/my_folder/python/py_projects/Mini_Projects/screenshots data\\\\{}.png'.format(name)\n",
        "    time.sleep(5) # 5 seconds after initialization ss os taken\n",
        "    # img = pyautogui.screenshot('ss1.png')\n",
        "    img = pyautogui.screenshot(name)\n",
        "    img.show()\n",
        "\n",
        "screenshot()"
      ],
      "metadata": {
        "id": "lzMSc-1pwJyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== SCREENSHOT GUI ===================================\n",
        "\n",
        "import time\n",
        "import pyautogui\n",
        "import tkinter as tk\n",
        "from tkinter import *\n",
        "\n",
        "def screenshot() :\n",
        "\n",
        "    name = int(round(time.time() * 1000))\n",
        "    name = 'D:/vs code/my_folder/python/py_projects/Mini_Projects/screenshots data\\\\{}.png'.format(name)\n",
        "    # time.sleep(5) # 5 seconds after initialization ss os taken\n",
        "    # img = pyautogui.screenshot('ss1.png')\n",
        "    img = pyautogui.screenshot(name)\n",
        "    img.show()\n",
        "\n",
        "window  = Tk()\n",
        "frame = Frame(window)\n",
        "frame.pack()\n",
        "\n",
        "btn = Button(frame, text= \"Take Screenshot\", command= screenshot)\n",
        "btn.pack(side = tk.LEFT)\n",
        "\n",
        "close = Button(frame, text= \"QUIT\", command= quit )\n",
        "close.pack(side = tk.LEFT)\n",
        "\n",
        "window.mainloop()\n",
        "\n"
      ],
      "metadata": {
        "id": "Bs_t-3w_wJ-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== SCREENSHOT GUI ===================================\n",
        "\n",
        "import time\n",
        "import pyautogui\n",
        "import tkinter as tk\n",
        "from tkinter import *\n",
        "\n",
        "def screenshot() :\n",
        "\n",
        "    name = int(round(time.time() * 1000))\n",
        "    name = 'D:/vs code/my_folder/python/py_projects/Mini_Projects/screenshots data\\\\{}.png'.format(name)\n",
        "    # time.sleep(5) # 5 seconds after initialization ss os taken\n",
        "    # img = pyautogui.screenshot('ss1.png')\n",
        "    img = pyautogui.screenshot(name)\n",
        "    img.show()\n",
        "\n",
        "window  = Tk()\n",
        "frame = Frame(window)\n",
        "frame.pack()\n",
        "\n",
        "btn = Button(frame, text= \"Take Screenshot\", command= screenshot)\n",
        "btn.pack(side = tk.LEFT)\n",
        "\n",
        "close = Button(frame, text= \"QUIT\", command= quit )\n",
        "close.pack(side = tk.LEFT)\n",
        "\n",
        "window.mainloop()"
      ],
      "metadata": {
        "id": "g5tc3V5Q0BTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== JARVIS ASSISTANT ===================================\n",
        "\n",
        "\n",
        "# pip install virtualenv\n",
        "# virtualenv jarvis and then activate\n",
        "# pip install pyttsx3\n",
        "# pip install SpeechRecognition\n",
        "\n",
        "import pyttsx3\n",
        "import speech_recognition as sr\n",
        "import datetime\n",
        "import wikipedia\n",
        "\n",
        "engine = pyttsx3.init('sapi5') # we use sapi5 object\n",
        "voices = engine.getProperty('voices') # get voices\n",
        "# print(voices[1].id)\n",
        "engine.setProperty(\"voice\", voices[0].id )\n",
        "\n",
        "def speak(audio):\n",
        "\n",
        "    engine.say(audio)\n",
        "    engine.runAndWait()\n",
        "\n",
        "def greet() :\n",
        "    speak(\"Welcome Back!\")\n",
        "    time = datetime.datetime.now().strftime(\"%I:%M:%S %p\") # Time format\n",
        "    # print(time)\n",
        "    speak(f\"The current time is {time}\")\n",
        "    speak(\"Please, Say out the thing about which you want to search...\")\n",
        "\n",
        "greet()\n",
        "\n",
        "\n",
        "\n",
        "# def wiki(query) :\n",
        "\n",
        "#     # query = input(\"Enter what you want to search about:\\n\")\n",
        "#     # results = wikipedia.summary(query, sentences = 3)\n",
        "#     q = query\n",
        "#     results = wikipedia.summary(q)\n",
        "#     speak(\"According to wikipedia\")\n",
        "#     # print(results)\n",
        "#     speak(results)\n",
        "\n",
        "def wiki(query):\n",
        "    try:\n",
        "        results = wikipedia.summary(query)\n",
        "        speak(\"According to Wikipedia:\")\n",
        "        print(results)\n",
        "        speak(results)\n",
        "    except wikipedia.exceptions.PageError:\n",
        "        speak(\"Sorry, I couldn't find any information on that topic.\")\n",
        "    except wikipedia.exceptions.DisambiguationError as e:\n",
        "        speak(\"There are multiple possible matches for that query. Please be more specific.\")\n",
        "    except Exception as e:\n",
        "        speak(\"An error occurred while trying to fetch information from Wikipedia.\")\n",
        "\n",
        "\n",
        "# wiki()\n",
        "\n",
        "def takeCommand():\n",
        "    r = sr.Recognizer() # tries to recognize the voice\n",
        "\n",
        "    with sr.Microphone() as source: # take input from microphone\n",
        "\n",
        "        print(\"Listening...\")\n",
        "        r.pause_threshold = 2 # pause for 2 sec indicates that user stops\n",
        "        audio = r.listen(source) # through source it will get the audio and convert the audio into the text format for processing\n",
        "\n",
        "    try :\n",
        "        print('Recognizing.....')\n",
        "        query = r.recognize_google(audio, language= 'en-in')\n",
        "        print(f\"Searhing :{query}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print('Sorry, Could you say that again')\n",
        "        speak(\"Sorry, Could you say it again\")\n",
        "        return \"None\"\n",
        "\n",
        "    return query\n",
        "\n",
        "query = takeCommand()\n",
        "wiki(query)"
      ],
      "metadata": {
        "id": "daitnPwC0EFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== JARVIS ASSISTANT2 ===================================\n",
        "\n",
        "# pip install virtualenv\n",
        "# virtualenv jarvis and then activate\n",
        "# pip install pyttsx3\n",
        "# pip install SpeechRecognition\n",
        "\n",
        "import pyttsx3\n",
        "import speech_recognition as sr\n",
        "import datetime\n",
        "import wikipedia\n",
        "from twilio.rest import Client\n",
        "import os\n",
        "import pygame\n",
        "\n",
        "engine = pyttsx3.init('sapi5') # we use sapi5 object\n",
        "voices = engine.getProperty('voices') # get voices\n",
        "# print(voices[1].id)\n",
        "engine.setProperty(\"voice\", voices[0].id )\n",
        "\n",
        "def speak(audio):\n",
        "\n",
        "    engine.say(audio)\n",
        "    engine.runAndWait()\n",
        "\n",
        "def greet() :\n",
        "    speak(\"Welcome Back!\")\n",
        "    time = datetime.datetime.now().strftime(\"%I:%M:%S %p\") # Time format\n",
        "    # print(time)\n",
        "    speak(f\"The current time is {time}\")\n",
        "    speak(\"Please, Say out the thing about which you want to search...\")\n",
        "\n",
        "greet()\n",
        "\n",
        "\n",
        "def wiki(query):\n",
        "    try:\n",
        "        results = wikipedia.summary(query)\n",
        "        speak(\"According to Wikipedia:\")\n",
        "        print(results)\n",
        "        speak(results)\n",
        "    except wikipedia.exceptions.PageError:\n",
        "        speak(\"Sorry, I couldn't find any information on that topic.\")\n",
        "    except wikipedia.exceptions.DisambiguationError as e:\n",
        "        speak(\"There are multiple possible matches for that query. Please be more specific.\")\n",
        "    except Exception as e:\n",
        "        speak(\"An error occurred while trying to fetch information from Wikipedia.\")\n",
        "\n",
        "\n",
        "# ===================== Voice-Controlled Text Messaging (Using Twilio)\n",
        "# pip install twilio\n",
        "\n",
        "# def send_text_message(to, message):\n",
        "#     # Your Twilio Account SID and Auth Token\n",
        "#     account_sid = 'your_account_sid'\n",
        "#     auth_token = 'your_auth_token'\n",
        "\n",
        "#     # Create a Twilio client\n",
        "#     client = Client(account_sid, auth_token)\n",
        "\n",
        "#     try:\n",
        "#         # Send the message\n",
        "#         message = client.messages.create(\n",
        "#             body=message,\n",
        "#             from_='your_twilio_phone_number',\n",
        "#             to=to\n",
        "#         )\n",
        "#         print(f\"Message sent: {message.sid}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error sending message: {str(e)}\")\n",
        "\n",
        "# # Usage\n",
        "# to = 'recipient_phone_number'\n",
        "# message = 'Hello, this is a test message.'\n",
        "# send_text_message(to, message)\n",
        "\n",
        "\n",
        "\n",
        "# ============================== Voice-Activated Music Player\n",
        "\n",
        "def play_music(folder_path):\n",
        "    # Initialize pygame mixer\n",
        "    pygame.mixer.init()\n",
        "\n",
        "    # List audio files in the specified folder\n",
        "    music_files = [f for f in os.listdir(folder_path) if f.endswith('.mp3')]\n",
        "\n",
        "    if not music_files:\n",
        "        print(\"No music files found in the specified folder.\")\n",
        "        return\n",
        "\n",
        "    # Select the first music file\n",
        "    music_file = os.path.join(folder_path, music_files[0])\n",
        "\n",
        "    # Load and play the selected music file\n",
        "    pygame.mixer.music.load(music_file)\n",
        "    pygame.mixer.music.play()\n",
        "\n",
        "# Usage\n",
        "folder_path = 'path_to_music_folder'\n",
        "play_music(folder_path)\n",
        "\n",
        "# wiki()\n",
        "\n",
        "def takeCommand():\n",
        "    r = sr.Recognizer() # tries to recognize the voice\n",
        "\n",
        "    with sr.Microphone() as source: # take input from microphone\n",
        "\n",
        "        print(\"Listening...\")\n",
        "        r.pause_threshold = 2 # pause for 2 sec indicates that user stops\n",
        "        audio = r.listen(source) # through source it will get the audio and convert the audio into the text format for processing\n",
        "\n",
        "    try :\n",
        "        print('Recognizing.....')\n",
        "        query = r.recognize_google(audio, language= 'en-in')\n",
        "        print(f\"Searhing :{query}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print('Sorry, Could you say that again')\n",
        "        speak(\"Sorry, Could you say it again\")\n",
        "        return \"None\"\n",
        "\n",
        "    return query\n",
        "\n",
        "query = takeCommand()\n",
        "wiki(query)\n",
        "\n"
      ],
      "metadata": {
        "id": "eNgdijam0UhT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}